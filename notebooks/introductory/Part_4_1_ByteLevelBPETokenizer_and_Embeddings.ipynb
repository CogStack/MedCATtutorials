{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "lXXf2emwSdpN",
    "outputId": "ca56a776-3574-48d4-9f4c-252690ef40f9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
      "Collecting medcat==1.3.0\n",
      " Downloading medcat-1.3.0-py3-none-any.whl (133 kB)\n",
      "\u001b[K |████████████████████████████████| 133 kB 6.8 MB/s \n",
      "\u001b[?25hRequirement already satisfied: click<=8.0.4 in /usr/local/lib/python3.7/dist-packages (from medcat==1.3.0) (7.1.2)\n",
      "Requirement already satisfied: pandas<=1.4.2,>=1.1.5 in /usr/local/lib/python3.7/dist-packages (from medcat==1.3.0) (1.3.5)\n",
      "Collecting xxhash==3.0.0\n",
      " Downloading xxhash-3.0.0-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (212 kB)\n",
      "\u001b[K |████████████████████████████████| 212 kB 48.2 MB/s \n",
      "\u001b[?25hCollecting gensim~=4.1.2\n",
      " Downloading gensim-4.1.2-cp37-cp37m-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (24.1 MB)\n",
      "\u001b[K |████████████████████████████████| 24.1 MB 2.0 MB/s \n",
      "\u001b[?25hCollecting aiofiles~=0.8.0\n",
      " Downloading aiofiles-0.8.0-py3-none-any.whl (13 kB)\n",
      "Collecting datasets~=2.2.2\n",
      " Downloading datasets-2.2.2-py3-none-any.whl (346 kB)\n",
      "\u001b[K |████████████████████████████████| 346 kB 47.7 MB/s \n",
      "\u001b[?25hCollecting py2neo==2021.2.3\n",
      " Downloading py2neo-2021.2.3-py2.py3-none-any.whl (177 kB)\n",
      "\u001b[K |████████████████████████████████| 177 kB 48.7 MB/s \n",
      "\u001b[?25hRequirement already satisfied: torch>=1.0 in /usr/local/lib/python3.7/dist-packages (from medcat==1.3.0) (1.12.1+cu113)\n",
      "Collecting transformers~=4.19.2\n",
      " Downloading transformers-4.19.4-py3-none-any.whl (4.2 MB)\n",
      "\u001b[K |████████████████████████████████| 4.2 MB 44.0 MB/s \n",
      "\u001b[?25hRequirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from medcat==1.3.0) (4.64.0)\n",
      "Collecting ipywidgets~=7.6.5\n",
      " Downloading ipywidgets-7.6.6-py2.py3-none-any.whl (121 kB)\n",
      "\u001b[K |████████████████████████████████| 121 kB 51.8 MB/s \n",
      "\u001b[?25hCollecting psutil<6.0.0,>=5.8.0\n",
      " Downloading psutil-5.9.1-cp37-cp37m-manylinux_2_12_x86_64.manylinux2010_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (281 kB)\n",
      "\u001b[K |████████████████████████████████| 281 kB 47.7 MB/s \n",
      "\u001b[?25hCollecting sklearn~=0.0\n",
      " Downloading sklearn-0.0.tar.gz (1.1 kB)\n",
      "Collecting spacy<3.1.4,>=3.1.0\n",
      " Downloading spacy-3.1.3-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (5.9 MB)\n",
      "\u001b[K |████████████████████████████████| 5.9 MB 37.4 MB/s \n",
      "\u001b[?25hCollecting elasticsearch<8.0.0,>=7.10\n",
      " Downloading elasticsearch-7.17.4-py2.py3-none-any.whl (385 kB)\n",
      "\u001b[K |████████████████████████████████| 385 kB 18.9 MB/s \n",
      "\u001b[?25hCollecting blis<=0.7.5\n",
      " Downloading blis-0.7.5-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (9.9 MB)\n",
      "\u001b[K |████████████████████████████████| 9.9 MB 33.4 MB/s \n",
      "\u001b[?25hRequirement already satisfied: dill~=0.3.4 in /usr/local/lib/python3.7/dist-packages (from medcat==1.3.0) (0.3.5.1)\n",
      "Collecting multiprocess\n",
      " Downloading multiprocess-0.70.13-py37-none-any.whl (115 kB)\n",
      "\u001b[K |████████████████████████████████| 115 kB 18.7 MB/s \n",
      "\u001b[?25hRequirement already satisfied: scipy<=1.8.1,>=1.5.4 in /usr/local/lib/python3.7/dist-packages (from medcat==1.3.0) (1.7.3)\n",
      "Collecting jsonpickle~=2.0.0\n",
      " Downloading jsonpickle-2.0.0-py2.py3-none-any.whl (37 kB)\n",
      "Requirement already satisfied: numpy>=1.21.4 in /usr/local/lib/python3.7/dist-packages (from medcat==1.3.0) (1.21.6)\n",
      "Requirement already satisfied: certifi in /usr/local/lib/python3.7/dist-packages (from py2neo==2021.2.3->medcat==1.3.0) (2022.6.15)\n",
      "Collecting pansi>=2020.7.3\n",
      " Downloading pansi-2020.7.3-py2.py3-none-any.whl (10 kB)\n",
      "Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from py2neo==2021.2.3->medcat==1.3.0) (21.3)\n",
      "Requirement already satisfied: urllib3 in /usr/local/lib/python3.7/dist-packages (from py2neo==2021.2.3->medcat==1.3.0) (1.24.3)\n",
      "Requirement already satisfied: six>=1.15.0 in /usr/local/lib/python3.7/dist-packages (from py2neo==2021.2.3->medcat==1.3.0) (1.15.0)\n",
      "Collecting monotonic\n",
      " Downloading monotonic-1.6-py2.py3-none-any.whl (8.2 kB)\n",
      "Collecting interchange~=2021.0.4\n",
      " Downloading interchange-2021.0.4-py2.py3-none-any.whl (28 kB)\n",
      "Requirement already satisfied: pygments>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from py2neo==2021.2.3->medcat==1.3.0) (2.6.1)\n",
      "Collecting dill~=0.3.4\n",
      " Downloading dill-0.3.4-py2.py3-none-any.whl (86 kB)\n",
      "\u001b[K |████████████████████████████████| 86 kB 8.4 MB/s \n",
      "\u001b[?25hCollecting huggingface-hub<1.0.0,>=0.1.0\n",
      " Downloading huggingface_hub-0.9.0-py3-none-any.whl (120 kB)\n",
      "\u001b[K |████████████████████████████████| 120 kB 62.7 MB/s \n",
      "\u001b[?25hRequirement already satisfied: fsspec[http]>=2021.05.0 in /usr/local/lib/python3.7/dist-packages (from datasets~=2.2.2->medcat==1.3.0) (2022.7.1)\n",
      "Requirement already satisfied: aiohttp in /usr/local/lib/python3.7/dist-packages (from datasets~=2.2.2->medcat==1.3.0) (3.8.1)\n",
      "Collecting responses<0.19\n",
      " Downloading responses-0.18.0-py3-none-any.whl (38 kB)\n",
      "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.7/dist-packages (from datasets~=2.2.2->medcat==1.3.0) (2.23.0)\n",
      "Requirement already satisfied: pyarrow>=6.0.0 in /usr/local/lib/python3.7/dist-packages (from datasets~=2.2.2->medcat==1.3.0) (6.0.1)\n",
      "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from datasets~=2.2.2->medcat==1.3.0) (4.12.0)\n",
      "Requirement already satisfied: smart-open>=1.8.1 in /usr/local/lib/python3.7/dist-packages (from gensim~=4.1.2->medcat==1.3.0) (5.2.1)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.7/dist-packages (from huggingface-hub<1.0.0,>=0.1.0->datasets~=2.2.2->medcat==1.3.0) (4.1.1)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from huggingface-hub<1.0.0,>=0.1.0->datasets~=2.2.2->medcat==1.3.0) (3.8.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.7/dist-packages (from huggingface-hub<1.0.0,>=0.1.0->datasets~=2.2.2->medcat==1.3.0) (6.0)\n",
      "Requirement already satisfied: pytz in /usr/local/lib/python3.7/dist-packages (from interchange~=2021.0.4->py2neo==2021.2.3->medcat==1.3.0) (2022.2.1)\n",
      "Collecting jupyterlab-widgets<3,>=1.0.0\n",
      " Downloading jupyterlab_widgets-1.1.1-py3-none-any.whl (245 kB)\n",
      "\u001b[K |████████████████████████████████| 245 kB 63.6 MB/s \n",
      "\u001b[?25hCollecting widgetsnbextension~=3.5.0\n",
      " Downloading widgetsnbextension-3.5.2-py2.py3-none-any.whl (1.6 MB)\n",
      "\u001b[K |████████████████████████████████| 1.6 MB 43.5 MB/s \n",
      "\u001b[?25hRequirement already satisfied: ipykernel>=4.5.1 in /usr/local/lib/python3.7/dist-packages (from ipywidgets~=7.6.5->medcat==1.3.0) (5.3.4)\n",
      "Requirement already satisfied: traitlets>=4.3.1 in /usr/local/lib/python3.7/dist-packages (from ipywidgets~=7.6.5->medcat==1.3.0) (5.1.1)\n",
      "Requirement already satisfied: ipython-genutils~=0.2.0 in /usr/local/lib/python3.7/dist-packages (from ipywidgets~=7.6.5->medcat==1.3.0) (0.2.0)\n",
      "Requirement already satisfied: nbformat>=4.2.0 in /usr/local/lib/python3.7/dist-packages (from ipywidgets~=7.6.5->medcat==1.3.0) (5.4.0)\n",
      "Requirement already satisfied: ipython>=4.0.0 in /usr/local/lib/python3.7/dist-packages (from ipywidgets~=7.6.5->medcat==1.3.0) (7.9.0)\n",
      "Requirement already satisfied: jupyter-client in /usr/local/lib/python3.7/dist-packages (from ipykernel>=4.5.1->ipywidgets~=7.6.5->medcat==1.3.0) (6.1.12)\n",
      "Requirement already satisfied: tornado>=4.2 in /usr/local/lib/python3.7/dist-packages (from ipykernel>=4.5.1->ipywidgets~=7.6.5->medcat==1.3.0) (5.1.1)\n",
      "Requirement already satisfied: pickleshare in /usr/local/lib/python3.7/dist-packages (from ipython>=4.0.0->ipywidgets~=7.6.5->medcat==1.3.0) (0.7.5)\n",
      "Requirement already satisfied: backcall in /usr/local/lib/python3.7/dist-packages (from ipython>=4.0.0->ipywidgets~=7.6.5->medcat==1.3.0) (0.2.0)\n",
      "Requirement already satisfied: prompt-toolkit<2.1.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from ipython>=4.0.0->ipywidgets~=7.6.5->medcat==1.3.0) (2.0.10)\n",
      "Requirement already satisfied: pexpect in /usr/local/lib/python3.7/dist-packages (from ipython>=4.0.0->ipywidgets~=7.6.5->medcat==1.3.0) (4.8.0)\n",
      "Requirement already satisfied: setuptools>=18.5 in /usr/local/lib/python3.7/dist-packages (from ipython>=4.0.0->ipywidgets~=7.6.5->medcat==1.3.0) (57.4.0)\n",
      "Collecting jedi>=0.10\n",
      " Downloading jedi-0.18.1-py2.py3-none-any.whl (1.6 MB)\n",
      "\u001b[K |████████████████████████████████| 1.6 MB 53.7 MB/s \n",
      "\u001b[?25hRequirement already satisfied: decorator in /usr/local/lib/python3.7/dist-packages (from ipython>=4.0.0->ipywidgets~=7.6.5->medcat==1.3.0) (4.4.2)\n",
      "Requirement already satisfied: parso<0.9.0,>=0.8.0 in /usr/local/lib/python3.7/dist-packages (from jedi>=0.10->ipython>=4.0.0->ipywidgets~=7.6.5->medcat==1.3.0) (0.8.3)\n",
      "Requirement already satisfied: fastjsonschema in /usr/local/lib/python3.7/dist-packages (from nbformat>=4.2.0->ipywidgets~=7.6.5->medcat==1.3.0) (2.16.1)\n",
      "Requirement already satisfied: jsonschema>=2.6 in /usr/local/lib/python3.7/dist-packages (from nbformat>=4.2.0->ipywidgets~=7.6.5->medcat==1.3.0) (4.3.3)\n",
      "Requirement already satisfied: jupyter-core in /usr/local/lib/python3.7/dist-packages (from nbformat>=4.2.0->ipywidgets~=7.6.5->medcat==1.3.0) (4.11.1)\n",
      "Requirement already satisfied: pyrsistent!=0.17.0,!=0.17.1,!=0.17.2,>=0.14.0 in /usr/local/lib/python3.7/dist-packages (from jsonschema>=2.6->nbformat>=4.2.0->ipywidgets~=7.6.5->medcat==1.3.0) (0.18.1)\n",
      "Requirement already satisfied: importlib-resources>=1.4.0 in /usr/local/lib/python3.7/dist-packages (from jsonschema>=2.6->nbformat>=4.2.0->ipywidgets~=7.6.5->medcat==1.3.0) (5.9.0)\n",
      "Requirement already satisfied: attrs>=17.4.0 in /usr/local/lib/python3.7/dist-packages (from jsonschema>=2.6->nbformat>=4.2.0->ipywidgets~=7.6.5->medcat==1.3.0) (22.1.0)\n",
      "Requirement already satisfied: zipp>=3.1.0 in /usr/local/lib/python3.7/dist-packages (from importlib-resources>=1.4.0->jsonschema>=2.6->nbformat>=4.2.0->ipywidgets~=7.6.5->medcat==1.3.0) (3.8.1)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->py2neo==2021.2.3->medcat==1.3.0) (3.0.9)\n",
      "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas<=1.4.2,>=1.1.5->medcat==1.3.0) (2.8.2)\n",
      "Requirement already satisfied: wcwidth in /usr/local/lib/python3.7/dist-packages (from prompt-toolkit<2.1.0,>=2.0.0->ipython>=4.0.0->ipywidgets~=7.6.5->medcat==1.3.0) (0.2.5)\n",
      "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->datasets~=2.2.2->medcat==1.3.0) (3.0.4)\n",
      "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->datasets~=2.2.2->medcat==1.3.0) (2.10)\n",
      "Collecting urllib3\n",
      " Downloading urllib3-1.25.11-py2.py3-none-any.whl (127 kB)\n",
      "\u001b[K |████████████████████████████████| 127 kB 77.0 MB/s \n",
      "\u001b[?25hRequirement already satisfied: scikit-learn in /usr/local/lib/python3.7/dist-packages (from sklearn~=0.0->medcat==1.3.0) (1.0.2)\n",
      "Collecting pydantic!=1.8,!=1.8.1,<1.9.0,>=1.7.4\n",
      " Downloading pydantic-1.8.2-cp37-cp37m-manylinux2014_x86_64.whl (10.1 MB)\n",
      "\u001b[K |████████████████████████████████| 10.1 MB 56.5 MB/s \n",
      "\u001b[?25hRequirement already satisfied: typer<0.5.0,>=0.3.0 in /usr/local/lib/python3.7/dist-packages (from spacy<3.1.4,>=3.1.0->medcat==1.3.0) (0.4.2)\n",
      "Requirement already satisfied: wasabi<1.1.0,>=0.8.1 in /usr/local/lib/python3.7/dist-packages (from spacy<3.1.4,>=3.1.0->medcat==1.3.0) (0.10.1)\n",
      "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.8 in /usr/local/lib/python3.7/dist-packages (from spacy<3.1.4,>=3.1.0->medcat==1.3.0) (3.0.10)\n",
      "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy<3.1.4,>=3.1.0->medcat==1.3.0) (3.0.7)\n",
      "Collecting typing-extensions>=3.7.4.3\n",
      " Downloading typing_extensions-3.10.0.2-py3-none-any.whl (26 kB)\n",
      "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.7/dist-packages (from spacy<3.1.4,>=3.1.0->medcat==1.3.0) (1.0.8)\n",
      "Collecting thinc<8.1.0,>=8.0.9\n",
      " Downloading thinc-8.0.17-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (660 kB)\n",
      "\u001b[K |████████████████████████████████| 660 kB 74.5 MB/s \n",
      "\u001b[?25hRequirement already satisfied: srsly<3.0.0,>=2.4.1 in /usr/local/lib/python3.7/dist-packages (from spacy<3.1.4,>=3.1.0->medcat==1.3.0) (2.4.4)\n",
      "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy<3.1.4,>=3.1.0->medcat==1.3.0) (2.0.6)\n",
      "Requirement already satisfied: pathy>=0.3.5 in /usr/local/lib/python3.7/dist-packages (from spacy<3.1.4,>=3.1.0->medcat==1.3.0) (0.6.2)\n",
      "Requirement already satisfied: jinja2 in /usr/local/lib/python3.7/dist-packages (from spacy<3.1.4,>=3.1.0->medcat==1.3.0) (2.11.3)\n",
      "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /usr/local/lib/python3.7/dist-packages (from spacy<3.1.4,>=3.1.0->medcat==1.3.0) (2.0.8)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers~=4.19.2->medcat==1.3.0) (2022.6.2)\n",
      "Collecting tokenizers!=0.11.3,<0.13,>=0.11.1\n",
      " Downloading tokenizers-0.12.1-cp37-cp37m-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (6.6 MB)\n",
      "\u001b[K |████████████████████████████████| 6.6 MB 44.9 MB/s \n",
      "\u001b[?25hRequirement already satisfied: notebook>=4.4.1 in /usr/local/lib/python3.7/dist-packages (from widgetsnbextension~=3.5.0->ipywidgets~=7.6.5->medcat==1.3.0) (5.3.1)\n",
      "Requirement already satisfied: nbconvert in /usr/local/lib/python3.7/dist-packages (from notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets~=7.6.5->medcat==1.3.0) (5.6.1)\n",
      "Requirement already satisfied: terminado>=0.8.1 in /usr/local/lib/python3.7/dist-packages (from notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets~=7.6.5->medcat==1.3.0) (0.13.3)\n",
      "Requirement already satisfied: Send2Trash in /usr/local/lib/python3.7/dist-packages (from notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets~=7.6.5->medcat==1.3.0) (1.8.0)\n",
      "Requirement already satisfied: pyzmq>=13 in /usr/local/lib/python3.7/dist-packages (from jupyter-client->ipykernel>=4.5.1->ipywidgets~=7.6.5->medcat==1.3.0) (23.2.1)\n",
      "Requirement already satisfied: ptyprocess in /usr/local/lib/python3.7/dist-packages (from terminado>=0.8.1->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets~=7.6.5->medcat==1.3.0) (0.7.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.7/dist-packages (from aiohttp->datasets~=2.2.2->medcat==1.3.0) (1.3.1)\n",
      "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /usr/local/lib/python3.7/dist-packages (from aiohttp->datasets~=2.2.2->medcat==1.3.0) (4.0.2)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.7/dist-packages (from aiohttp->datasets~=2.2.2->medcat==1.3.0) (1.8.1)\n",
      "Requirement already satisfied: asynctest==0.13.0 in /usr/local/lib/python3.7/dist-packages (from aiohttp->datasets~=2.2.2->medcat==1.3.0) (0.13.0)\n",
      "Requirement already satisfied: charset-normalizer<3.0,>=2.0 in /usr/local/lib/python3.7/dist-packages (from aiohttp->datasets~=2.2.2->medcat==1.3.0) (2.1.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.7/dist-packages (from aiohttp->datasets~=2.2.2->medcat==1.3.0) (6.0.2)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.7/dist-packages (from aiohttp->datasets~=2.2.2->medcat==1.3.0) (1.2.0)\n",
      "Requirement already satisfied: MarkupSafe>=0.23 in /usr/local/lib/python3.7/dist-packages (from jinja2->spacy<3.1.4,>=3.1.0->medcat==1.3.0) (2.0.1)\n",
      "Collecting multiprocess\n",
      " Downloading multiprocess-0.70.12.2-py37-none-any.whl (112 kB)\n",
      "\u001b[K |████████████████████████████████| 112 kB 61.9 MB/s \n",
      "\u001b[?25hRequirement already satisfied: entrypoints>=0.2.2 in /usr/local/lib/python3.7/dist-packages (from nbconvert->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets~=7.6.5->medcat==1.3.0) (0.4)\n",
      "Requirement already satisfied: mistune<2,>=0.8.1 in /usr/local/lib/python3.7/dist-packages (from nbconvert->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets~=7.6.5->medcat==1.3.0) (0.8.4)\n",
      "Requirement already satisfied: defusedxml in /usr/local/lib/python3.7/dist-packages (from nbconvert->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets~=7.6.5->medcat==1.3.0) (0.7.1)\n",
      "Requirement already satisfied: pandocfilters>=1.4.1 in /usr/local/lib/python3.7/dist-packages (from nbconvert->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets~=7.6.5->medcat==1.3.0) (1.5.0)\n",
      "Requirement already satisfied: bleach in /usr/local/lib/python3.7/dist-packages (from nbconvert->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets~=7.6.5->medcat==1.3.0) (5.0.1)\n",
      "Requirement already satisfied: testpath in /usr/local/lib/python3.7/dist-packages (from nbconvert->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets~=7.6.5->medcat==1.3.0) (0.6.0)\n",
      "Requirement already satisfied: webencodings in /usr/local/lib/python3.7/dist-packages (from bleach->nbconvert->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets~=7.6.5->medcat==1.3.0) (0.5.1)\n",
      "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.7/dist-packages (from scikit-learn->sklearn~=0.0->medcat==1.3.0) (1.1.0)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn->sklearn~=0.0->medcat==1.3.0) (3.1.0)\n",
      "Building wheels for collected packages: sklearn\n",
      " Building wheel for sklearn (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      " Created wheel for sklearn: filename=sklearn-0.0-py2.py3-none-any.whl size=1310 sha256=d997d03bee04b40968c88f9108dc895e6153bf0c3e945f52377127d731ed5ee0\n",
      " Stored in directory: /root/.cache/pip/wheels/46/ef/c3/157e41f5ee1372d1be90b09f74f82b10e391eaacca8f22d33e\n",
      "Successfully built sklearn\n",
      "Installing collected packages: typing-extensions, jedi, urllib3, pydantic, dill, blis, xxhash, widgetsnbextension, tokenizers, thinc, responses, pansi, multiprocess, monotonic, jupyterlab-widgets, interchange, huggingface-hub, transformers, spacy, sklearn, py2neo, psutil, jsonpickle, ipywidgets, gensim, elasticsearch, datasets, aiofiles, medcat\n",
      " Attempting uninstall: typing-extensions\n",
      " Found existing installation: typing-extensions 4.1.1\n",
      " Uninstalling typing-extensions-4.1.1:\n",
      " Successfully uninstalled typing-extensions-4.1.1\n",
      " Attempting uninstall: urllib3\n",
      " Found existing installation: urllib3 1.24.3\n",
      " Uninstalling urllib3-1.24.3:\n",
      " Successfully uninstalled urllib3-1.24.3\n",
      " Attempting uninstall: pydantic\n",
      " Found existing installation: pydantic 1.9.2\n",
      " Uninstalling pydantic-1.9.2:\n",
      " Successfully uninstalled pydantic-1.9.2\n",
      " Attempting uninstall: dill\n",
      " Found existing installation: dill 0.3.5.1\n",
      " Uninstalling dill-0.3.5.1:\n",
      " Successfully uninstalled dill-0.3.5.1\n",
      " Attempting uninstall: blis\n",
      " Found existing installation: blis 0.7.8\n",
      " Uninstalling blis-0.7.8:\n",
      " Successfully uninstalled blis-0.7.8\n",
      " Attempting uninstall: widgetsnbextension\n",
      " Found existing installation: widgetsnbextension 3.6.1\n",
      " Uninstalling widgetsnbextension-3.6.1:\n",
      " Successfully uninstalled widgetsnbextension-3.6.1\n",
      " Attempting uninstall: thinc\n",
      " Found existing installation: thinc 8.1.0\n",
      " Uninstalling thinc-8.1.0:\n",
      " Successfully uninstalled thinc-8.1.0\n",
      " Attempting uninstall: jupyterlab-widgets\n",
      " Found existing installation: jupyterlab-widgets 3.0.2\n",
      " Uninstalling jupyterlab-widgets-3.0.2:\n",
      " Successfully uninstalled jupyterlab-widgets-3.0.2\n",
      " Attempting uninstall: spacy\n",
      " Found existing installation: spacy 3.4.1\n",
      " Uninstalling spacy-3.4.1:\n",
      " Successfully uninstalled spacy-3.4.1\n",
      " Attempting uninstall: psutil\n",
      " Found existing installation: psutil 5.4.8\n",
      " Uninstalling psutil-5.4.8:\n",
      " Successfully uninstalled psutil-5.4.8\n",
      " Attempting uninstall: ipywidgets\n",
      " Found existing installation: ipywidgets 7.7.1\n",
      " Uninstalling ipywidgets-7.7.1:\n",
      " Successfully uninstalled ipywidgets-7.7.1\n",
      " Attempting uninstall: gensim\n",
      " Found existing installation: gensim 3.6.0\n",
      " Uninstalling gensim-3.6.0:\n",
      " Successfully uninstalled gensim-3.6.0\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "en-core-web-sm 3.4.0 requires spacy<3.5.0,>=3.4.0, but you have spacy 3.1.3 which is incompatible.\u001b[0m\n",
      "Successfully installed aiofiles-0.8.0 blis-0.7.5 datasets-2.2.2 dill-0.3.4 elasticsearch-7.17.4 gensim-4.1.2 huggingface-hub-0.9.0 interchange-2021.0.4 ipywidgets-7.6.6 jedi-0.18.1 jsonpickle-2.0.0 jupyterlab-widgets-1.1.1 medcat-1.3.0 monotonic-1.6 multiprocess-0.70.12.2 pansi-2020.7.3 psutil-5.9.1 py2neo-2021.2.3 pydantic-1.8.2 responses-0.18.0 sklearn-0.0 spacy-3.1.3 thinc-8.0.17 tokenizers-0.12.1 transformers-4.19.4 typing-extensions-3.10.0.2 urllib3-1.25.11 widgetsnbextension-3.5.2 xxhash-3.0.0\n"
     ]
    },
    {
     "data": {
      "application/vnd.colab-display-data+json": {
       "pip_warning": {
        "packages": [
         "psutil",
         "typing_extensions"
        ]
       }
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: Runtime will restart automatically and please run other cells thereafter.\n"
     ]
    }
   ],
   "source": [
    "# Install medcat\n",
    "! pip install medcat==1.5.0\n",
    "try:\n",
    "    from medcat.cat import CAT\n",
    "except:\n",
    "    print(\"WARNING: Runtime will restart automatically and please run other cells thereafter.\")\n",
    "    exit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "9jj679NkSfsS"
   },
   "outputs": [],
   "source": [
    "import gensim\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tokenizers import ByteLevelBPETokenizer\n",
    "from gensim.models import Word2Vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "nFwGQA3tSzF4"
   },
   "outputs": [],
   "source": [
    "DATA_DIR = \"./data/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "mR1Hqh5wSPaD",
    "outputId": "8d382711-84ac-4d1e-b20e-f17d895da7de"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mkdir: cannot create directory ‘./data’: File exists\n",
      "mkdir: cannot create directory ‘./models’: File exists\n",
      "--2022-08-25 11:42:26-- https://raw.githubusercontent.com/CogStack/MedCATtutorials/main/notebooks/introductory/data/noteevents.csv\n",
      "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.110.133, 185.199.108.133, 185.199.111.133, ...\n",
      "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.110.133|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 7171226 (6.8M) [text/plain]\n",
      "Saving to: ‘./data/noteevents.csv.1’\n",
      "\n",
      "noteevents.csv.1 100%[===================>] 6.84M --.-KB/s in 0.05s \n",
      "\n",
      "2022-08-25 11:42:27 (129 MB/s) - ‘./data/noteevents.csv.1’ saved [7171226/7171226]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!mkdir ./data\n",
    "!mkdir ./models\n",
    "!wget https://raw.githubusercontent.com/CogStack/MedCATtutorials/main/notebooks/introductory/data/noteevents.csv -P ./data/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tDBI5vy2VQRH"
   },
   "source": [
    "### Meta Annotations with MedCAT\n",
    "\n",
    "To train meta-annotations (e.g. Experiencer, Negation...) we need two additional models:\n",
    "- Tokenizer: to tokenize the text\n",
    "- Embeddings: Word2Vec or any other type of embeddings that will be used for meta annotations. \n",
    "\n",
    "For meta-annotations we will use a custom BiLSTM model with simulated attention that works very well with sub-word tokenizers and embeddings creating using Word2Vec or BERT (for simplicity we will use w2v here). All of this is also available for download (check next tutorial) and we only need to rebuild the tokenizer/embeddings if our use-case is from a very specific domain. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 169
    },
    "id": "K0ihb0tLSlRu",
    "outputId": "ef6d7c3a-600d-4524-807d-d9f73108d8f1"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       " <div id=\"df-ccf2574a-22fe-4207-aae2-08d2cf3ba90a\">\n",
       " <div class=\"colab-df-container\">\n",
       " <div>\n",
       "<style scoped>\n",
       " .dataframe tbody tr th:only-of-type {\n",
       " vertical-align: middle;\n",
       " }\n",
       "\n",
       " .dataframe tbody tr th {\n",
       " vertical-align: top;\n",
       " }\n",
       "\n",
       " .dataframe thead th {\n",
       " text-align: right;\n",
       " }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       " <thead>\n",
       " <tr style=\"text-align: right;\">\n",
       " <th></th>\n",
       " <th>Unnamed: 0</th>\n",
       " <th>subject_id</th>\n",
       " <th>chartdate</th>\n",
       " <th>category</th>\n",
       " <th>text</th>\n",
       " </tr>\n",
       " </thead>\n",
       " <tbody>\n",
       " <tr>\n",
       " <th>0</th>\n",
       " <td>0</td>\n",
       " <td>0</td>\n",
       " <td>01/01/2086</td>\n",
       " <td>Urology</td>\n",
       " <td>CHIEF COMPLAINT: , Blood in urine.,HISTORY OF ...</td>\n",
       " </tr>\n",
       " <tr>\n",
       " <th>1</th>\n",
       " <td>1</td>\n",
       " <td>0</td>\n",
       " <td>01/01/2086</td>\n",
       " <td>Emergency Room Reports</td>\n",
       " <td>CHIEF COMPLAINT: , Blood in urine.,HISTORY OF ...</td>\n",
       " </tr>\n",
       " <tr>\n",
       " <th>2</th>\n",
       " <td>2</td>\n",
       " <td>0</td>\n",
       " <td>01/01/2086</td>\n",
       " <td>General Medicine</td>\n",
       " <td>CHIEF COMPLAINT: , Blood in urine.,HISTORY OF ...</td>\n",
       " </tr>\n",
       " <tr>\n",
       " <th>3</th>\n",
       " <td>3</td>\n",
       " <td>0</td>\n",
       " <td>01/01/2086</td>\n",
       " <td>General Medicine</td>\n",
       " <td>CHIEF COMPLAINT:, Followup on hypertension an...</td>\n",
       " </tr>\n",
       " <tr>\n",
       " <th>4</th>\n",
       " <td>4</td>\n",
       " <td>0</td>\n",
       " <td>01/01/2086</td>\n",
       " <td>Consult - History and Phy.</td>\n",
       " <td>CHIEF COMPLAINT: , Blood in urine.,HISTORY OF ...</td>\n",
       " </tr>\n",
       " </tbody>\n",
       "</table>\n",
       "</div>\n",
       " <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-ccf2574a-22fe-4207-aae2-08d2cf3ba90a')\"\n",
       " title=\"Convert this dataframe to an interactive table.\"\n",
       " style=\"display:none;\">\n",
       " \n",
       " <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
       " width=\"24px\">\n",
       " <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
       " <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
       " </svg>\n",
       " </button>\n",
       " \n",
       " <style>\n",
       " .colab-df-container {\n",
       " display:flex;\n",
       " flex-wrap:wrap;\n",
       " gap: 12px;\n",
       " }\n",
       "\n",
       " .colab-df-convert {\n",
       " background-color: #E8F0FE;\n",
       " border: none;\n",
       " border-radius: 50%;\n",
       " cursor: pointer;\n",
       " display: none;\n",
       " fill: #1967D2;\n",
       " height: 32px;\n",
       " padding: 0 0 0 0;\n",
       " width: 32px;\n",
       " }\n",
       "\n",
       " .colab-df-convert:hover {\n",
       " background-color: #E2EBFA;\n",
       " box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
       " fill: #174EA6;\n",
       " }\n",
       "\n",
       " [theme=dark] .colab-df-convert {\n",
       " background-color: #3B4455;\n",
       " fill: #D2E3FC;\n",
       " }\n",
       "\n",
       " [theme=dark] .colab-df-convert:hover {\n",
       " background-color: #434B5C;\n",
       " box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
       " filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
       " fill: #FFFFFF;\n",
       " }\n",
       " </style>\n",
       "\n",
       " <script>\n",
       " const buttonEl =\n",
       " document.querySelector('#df-ccf2574a-22fe-4207-aae2-08d2cf3ba90a button.colab-df-convert');\n",
       " buttonEl.style.display =\n",
       " google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
       "\n",
       " async function convertToInteractive(key) {\n",
       " const element = document.querySelector('#df-ccf2574a-22fe-4207-aae2-08d2cf3ba90a');\n",
       " const dataTable =\n",
       " await google.colab.kernel.invokeFunction('convertToInteractive',\n",
       " [key], {});\n",
       " if (!dataTable) return;\n",
       "\n",
       " const docLinkHtml = 'Like what you see? Visit the ' +\n",
       " '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
       " + ' to learn more about interactive tables.';\n",
       " element.innerHTML = '';\n",
       " dataTable['output_type'] = 'display_data';\n",
       " await google.colab.output.renderOutput(dataTable, element);\n",
       " const docLink = document.createElement('div');\n",
       " docLink.innerHTML = docLinkHtml;\n",
       " element.appendChild(docLink);\n",
       " }\n",
       " </script>\n",
       " </div>\n",
       " </div>\n",
       " "
      ],
      "text/plain": [
       " Unnamed: 0 subject_id chartdate category \\\n",
       "0 0 0 01/01/2086 Urology \n",
       "1 1 0 01/01/2086 Emergency Room Reports \n",
       "2 2 0 01/01/2086 General Medicine \n",
       "3 3 0 01/01/2086 General Medicine \n",
       "4 4 0 01/01/2086 Consult - History and Phy. \n",
       "\n",
       " text \n",
       "0 CHIEF COMPLAINT: , Blood in urine.,HISTORY OF ... \n",
       "1 CHIEF COMPLAINT: , Blood in urine.,HISTORY OF ... \n",
       "2 CHIEF COMPLAINT: , Blood in urine.,HISTORY OF ... \n",
       "3 CHIEF COMPLAINT:, Followup on hypertension an... \n",
       "4 CHIEF COMPLAINT: , Blood in urine.,HISTORY OF ... "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# To train the tokenizer we will use all the data we have from our dummy dataset.\n",
    "df = pd.read_csv(DATA_DIR + \"noteevents.csv\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "sBtVgjCZS0gF"
   },
   "outputs": [],
   "source": [
    "# The tokenizers from huggingface require us to save all the text used for \n",
    "#training into one/multiple text files.\n",
    "f = open(DATA_DIR + \"tok_data.txt\", 'w')\n",
    "for text in df['text'].values:\n",
    "    #We'll remove new lines, so that we have one document in one line\n",
    "    text = text.strip().replace(\"\\n\", ' ')\n",
    "    f.write(text.lower()) # Lowercase text to remove noise\n",
    "    f.write(\"\\n\")\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "dukwUnN1TPCg"
   },
   "outputs": [],
   "source": [
    "# Create, train and save the tokenizer\n",
    "tokenizer = ByteLevelBPETokenizer()\n",
    "tokenizer.train(DATA_DIR + \"tok_data.txt\")\n",
    "tokenizer.save(\"./models/bbpe\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "Mh9uCi6ETiH3"
   },
   "outputs": [],
   "source": [
    "# Now we tokenize all the text we have and train word2vec\n",
    "f = open(DATA_DIR + \"tok_data.txt\", 'r')\n",
    "# Note that if you have a very large dataset, use iterators that\n",
    "#read the text line by line from the file, do not load the whole file\n",
    "#into memory.\n",
    "data = []\n",
    "for line in f:\n",
    "    data.append(tokenizer.encode(line).tokens)\n",
    "w2v = Word2Vec(data, vector_size=300, min_count=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "oMhwMcGI7Oqz",
    "outputId": "627d57b3-655e-4f91-ceb6-0ece715fc44d"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Ġmetastatic', 0.7546937465667725),\n",
       " ('Ġcolon', 0.7531586289405823),\n",
       " ('Ġbreast', 0.7017560601234436),\n",
       " ('Ġcarcinoma', 0.6899590492248535),\n",
       " ('Ġaugmentation', 0.6884581446647644),\n",
       " ('Ġca', 0.6584445834159851),\n",
       " ('Ġfamily', 0.657872200012207),\n",
       " ('Ġmesothelioma', 0.6546629071235657),\n",
       " ('Ġfather', 0.6540331244468689),\n",
       " ('Ġmother', 0.6450846791267395)]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check is word2vec trained, Ġ - for this tokenizer denotes start of word (a space)\n",
    "w2v.wv.most_similar('Ġcancer')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "DrRr4Pd_UgvY"
   },
   "outputs": [],
   "source": [
    "# Now we just have to create the embeddings matrix\n",
    "embeddings = []\n",
    "for i in range(tokenizer.get_vocab_size()):\n",
    "    word = tokenizer.id_to_token(i)\n",
    "    if word in w2v.wv:\n",
    "        embeddings.append(w2v.wv[word])\n",
    "    else:\n",
    "        # Assign a random vector if the word was not frequent enough to receive\n",
    "        #an embedding\n",
    "        embeddings.append(np.random.rand(300))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "Hz465LmIVD2E"
   },
   "outputs": [],
   "source": [
    "# Save the embeddings\n",
    "np.save(open(\"./models/embeddings.npy\", 'wb'), np.array(embeddings))"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "MedCAT Tutorial | Part 4.1 - ByteLevelBPETokenizer and Embeddings.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3.8.5 ('.venv': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "vscode": {
   "interpreter": {
    "hash": "60954f76b319195d8b66f263176ecf047c3a086773bff2d42e03144b47421836"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
