{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s_j_Gu7s3wTO"
      },
      "source": [
        "# Let's build and initialise a MedCAT model!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i4bQfWfXlKWJ"
      },
      "source": [
        "### First we need to install MedCAT\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "OlMQ2iQrlG69",
        "outputId": "d88a3871-5dc0-4c67-a19a-c24c9b638858"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting medcat==1.2.7\n",
            "  Downloading medcat-1.2.7-py3-none-any.whl (141 kB)\n",
            "\u001b[K     |████████████████████████████████| 141 kB 17.3 MB/s \n",
            "\u001b[?25hCollecting psutil<6.0.0,>=5.8.0\n",
            "  Downloading psutil-5.9.0-cp37-cp37m-manylinux_2_12_x86_64.manylinux2010_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (280 kB)\n",
            "\u001b[K     |████████████████████████████████| 280 kB 47.5 MB/s \n",
            "\u001b[?25hRequirement already satisfied: ipywidgets~=7.6.5 in /usr/local/lib/python3.7/dist-packages (from medcat==1.2.7) (7.6.5)\n",
            "Collecting gensim~=4.1.2\n",
            "  Downloading gensim-4.1.2-cp37-cp37m-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (24.1 MB)\n",
            "\u001b[K     |████████████████████████████████| 24.1 MB 3.4 MB/s \n",
            "\u001b[?25hCollecting spacy<3.1.4,>=3.1.0\n",
            "  Downloading spacy-3.1.3-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (5.9 MB)\n",
            "\u001b[K     |████████████████████████████████| 5.9 MB 45.9 MB/s \n",
            "\u001b[?25hCollecting elasticsearch>=7.10\n",
            "  Downloading elasticsearch-8.0.0-py3-none-any.whl (369 kB)\n",
            "\u001b[K     |████████████████████████████████| 369 kB 48.3 MB/s \n",
            "\u001b[?25hRequirement already satisfied: multiprocess in /usr/local/lib/python3.7/dist-packages (from medcat==1.2.7) (0.70.12.2)\n",
            "Collecting numpy<1.22.9,>=1.21.4\n",
            "  Downloading numpy-1.21.5-cp37-cp37m-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (15.7 MB)\n",
            "\u001b[K     |████████████████████████████████| 15.7 MB 41.3 MB/s \n",
            "\u001b[?25hRequirement already satisfied: sklearn~=0.0 in /usr/local/lib/python3.7/dist-packages (from medcat==1.2.7) (0.0)\n",
            "Requirement already satisfied: dill~=0.3.4 in /usr/local/lib/python3.7/dist-packages (from medcat==1.2.7) (0.3.4)\n",
            "Collecting py2neo==2021.2.3\n",
            "  Downloading py2neo-2021.2.3-py2.py3-none-any.whl (177 kB)\n",
            "\u001b[K     |████████████████████████████████| 177 kB 47.5 MB/s \n",
            "\u001b[?25hCollecting xxhash==2.0.2\n",
            "  Downloading xxhash-2.0.2-cp37-cp37m-manylinux2010_x86_64.whl (243 kB)\n",
            "\u001b[K     |████████████████████████████████| 243 kB 42.2 MB/s \n",
            "\u001b[?25hCollecting transformers~=4.11.3\n",
            "  Downloading transformers-4.11.3-py3-none-any.whl (2.9 MB)\n",
            "\u001b[K     |████████████████████████████████| 2.9 MB 9.4 MB/s \n",
            "\u001b[?25hRequirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from medcat==1.2.7) (4.62.3)\n",
            "Collecting datasets~=1.14.0\n",
            "  Downloading datasets-1.14.0-py3-none-any.whl (290 kB)\n",
            "\u001b[K     |████████████████████████████████| 290 kB 47.3 MB/s \n",
            "\u001b[?25hCollecting scipy<=1.7.1,>=1.5.4\n",
            "  Downloading scipy-1.7.1-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.whl (28.5 MB)\n",
            "\u001b[K     |████████████████████████████████| 28.5 MB 1.6 MB/s \n",
            "\u001b[?25hCollecting torch<1.10,>=1.0\n",
            "  Downloading torch-1.9.1-cp37-cp37m-manylinux1_x86_64.whl (831.4 MB)\n",
            "\u001b[K     |████████████████████████████████| 831.4 MB 6.3 kB/s \n",
            "\u001b[?25hCollecting pandas<=1.3.4,>=1.1.5\n",
            "  Downloading pandas-1.3.4-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (11.3 MB)\n",
            "\u001b[K     |████████████████████████████████| 11.3 MB 47.5 MB/s \n",
            "\u001b[?25hCollecting aiofiles~=0.8.0\n",
            "  Downloading aiofiles-0.8.0-py3-none-any.whl (13 kB)\n",
            "Collecting jsonpickle~=2.0.0\n",
            "  Downloading jsonpickle-2.0.0-py2.py3-none-any.whl (37 kB)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from py2neo==2021.2.3->medcat==1.2.7) (21.3)\n",
            "Requirement already satisfied: urllib3 in /usr/local/lib/python3.7/dist-packages (from py2neo==2021.2.3->medcat==1.2.7) (1.24.3)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.7/dist-packages (from py2neo==2021.2.3->medcat==1.2.7) (2021.10.8)\n",
            "Collecting monotonic\n",
            "  Downloading monotonic-1.6-py2.py3-none-any.whl (8.2 kB)\n",
            "Requirement already satisfied: six>=1.15.0 in /usr/local/lib/python3.7/dist-packages (from py2neo==2021.2.3->medcat==1.2.7) (1.15.0)\n",
            "Collecting pansi>=2020.7.3\n",
            "  Downloading pansi-2020.7.3-py2.py3-none-any.whl (10 kB)\n",
            "Collecting interchange~=2021.0.4\n",
            "  Downloading interchange-2021.0.4-py2.py3-none-any.whl (28 kB)\n",
            "Requirement already satisfied: pygments>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from py2neo==2021.2.3->medcat==1.2.7) (2.6.1)\n",
            "Requirement already satisfied: pyarrow!=4.0.0,>=1.0.0 in /usr/local/lib/python3.7/dist-packages (from datasets~=1.14.0->medcat==1.2.7) (6.0.1)\n",
            "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.7/dist-packages (from datasets~=1.14.0->medcat==1.2.7) (2.23.0)\n",
            "Collecting huggingface-hub<0.1.0,>=0.0.19\n",
            "  Downloading huggingface_hub-0.0.19-py3-none-any.whl (56 kB)\n",
            "\u001b[K     |████████████████████████████████| 56 kB 4.1 MB/s \n",
            "\u001b[?25hRequirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from datasets~=1.14.0->medcat==1.2.7) (4.10.1)\n",
            "Collecting fsspec[http]>=2021.05.0\n",
            "  Downloading fsspec-2022.1.0-py3-none-any.whl (133 kB)\n",
            "\u001b[K     |████████████████████████████████| 133 kB 61.8 MB/s \n",
            "\u001b[?25hCollecting aiohttp\n",
            "  Downloading aiohttp-3.8.1-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (1.1 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.1 MB 55.9 MB/s \n",
            "\u001b[?25hCollecting elastic-transport<9,>=8\n",
            "  Downloading elastic_transport-8.0.1-py3-none-any.whl (57 kB)\n",
            "\u001b[K     |████████████████████████████████| 57 kB 4.2 MB/s \n",
            "\u001b[?25hCollecting urllib3\n",
            "  Downloading urllib3-1.26.8-py2.py3-none-any.whl (138 kB)\n",
            "\u001b[K     |████████████████████████████████| 138 kB 57.5 MB/s \n",
            "\u001b[?25hRequirement already satisfied: smart-open>=1.8.1 in /usr/local/lib/python3.7/dist-packages (from gensim~=4.1.2->medcat==1.2.7) (5.2.1)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.7/dist-packages (from huggingface-hub<0.1.0,>=0.0.19->datasets~=1.14.0->medcat==1.2.7) (3.13)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from huggingface-hub<0.1.0,>=0.0.19->datasets~=1.14.0->medcat==1.2.7) (3.10.0.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from huggingface-hub<0.1.0,>=0.0.19->datasets~=1.14.0->medcat==1.2.7) (3.4.2)\n",
            "Requirement already satisfied: pytz in /usr/local/lib/python3.7/dist-packages (from interchange~=2021.0.4->py2neo==2021.2.3->medcat==1.2.7) (2018.9)\n",
            "Requirement already satisfied: ipython-genutils~=0.2.0 in /usr/local/lib/python3.7/dist-packages (from ipywidgets~=7.6.5->medcat==1.2.7) (0.2.0)\n",
            "Requirement already satisfied: widgetsnbextension~=3.5.0 in /usr/local/lib/python3.7/dist-packages (from ipywidgets~=7.6.5->medcat==1.2.7) (3.5.2)\n",
            "Requirement already satisfied: nbformat>=4.2.0 in /usr/local/lib/python3.7/dist-packages (from ipywidgets~=7.6.5->medcat==1.2.7) (5.1.3)\n",
            "Requirement already satisfied: ipykernel>=4.5.1 in /usr/local/lib/python3.7/dist-packages (from ipywidgets~=7.6.5->medcat==1.2.7) (4.10.1)\n",
            "Requirement already satisfied: jupyterlab-widgets>=1.0.0 in /usr/local/lib/python3.7/dist-packages (from ipywidgets~=7.6.5->medcat==1.2.7) (1.0.2)\n",
            "Requirement already satisfied: ipython>=4.0.0 in /usr/local/lib/python3.7/dist-packages (from ipywidgets~=7.6.5->medcat==1.2.7) (5.5.0)\n",
            "Requirement already satisfied: traitlets>=4.3.1 in /usr/local/lib/python3.7/dist-packages (from ipywidgets~=7.6.5->medcat==1.2.7) (5.1.1)\n",
            "Requirement already satisfied: jupyter-client in /usr/local/lib/python3.7/dist-packages (from ipykernel>=4.5.1->ipywidgets~=7.6.5->medcat==1.2.7) (5.3.5)\n",
            "Requirement already satisfied: tornado>=4.0 in /usr/local/lib/python3.7/dist-packages (from ipykernel>=4.5.1->ipywidgets~=7.6.5->medcat==1.2.7) (5.1.1)\n",
            "Requirement already satisfied: setuptools>=18.5 in /usr/local/lib/python3.7/dist-packages (from ipython>=4.0.0->ipywidgets~=7.6.5->medcat==1.2.7) (57.4.0)\n",
            "Requirement already satisfied: decorator in /usr/local/lib/python3.7/dist-packages (from ipython>=4.0.0->ipywidgets~=7.6.5->medcat==1.2.7) (4.4.2)\n",
            "Requirement already satisfied: pexpect in /usr/local/lib/python3.7/dist-packages (from ipython>=4.0.0->ipywidgets~=7.6.5->medcat==1.2.7) (4.8.0)\n",
            "Requirement already satisfied: pickleshare in /usr/local/lib/python3.7/dist-packages (from ipython>=4.0.0->ipywidgets~=7.6.5->medcat==1.2.7) (0.7.5)\n",
            "Requirement already satisfied: simplegeneric>0.8 in /usr/local/lib/python3.7/dist-packages (from ipython>=4.0.0->ipywidgets~=7.6.5->medcat==1.2.7) (0.8.1)\n",
            "Requirement already satisfied: prompt-toolkit<2.0.0,>=1.0.4 in /usr/local/lib/python3.7/dist-packages (from ipython>=4.0.0->ipywidgets~=7.6.5->medcat==1.2.7) (1.0.18)\n",
            "Requirement already satisfied: jupyter-core in /usr/local/lib/python3.7/dist-packages (from nbformat>=4.2.0->ipywidgets~=7.6.5->medcat==1.2.7) (4.9.1)\n",
            "Requirement already satisfied: jsonschema!=2.5.0,>=2.4 in /usr/local/lib/python3.7/dist-packages (from nbformat>=4.2.0->ipywidgets~=7.6.5->medcat==1.2.7) (4.3.3)\n",
            "Requirement already satisfied: attrs>=17.4.0 in /usr/local/lib/python3.7/dist-packages (from jsonschema!=2.5.0,>=2.4->nbformat>=4.2.0->ipywidgets~=7.6.5->medcat==1.2.7) (21.4.0)\n",
            "Requirement already satisfied: importlib-resources>=1.4.0 in /usr/local/lib/python3.7/dist-packages (from jsonschema!=2.5.0,>=2.4->nbformat>=4.2.0->ipywidgets~=7.6.5->medcat==1.2.7) (5.4.0)\n",
            "Requirement already satisfied: pyrsistent!=0.17.0,!=0.17.1,!=0.17.2,>=0.14.0 in /usr/local/lib/python3.7/dist-packages (from jsonschema!=2.5.0,>=2.4->nbformat>=4.2.0->ipywidgets~=7.6.5->medcat==1.2.7) (0.18.1)\n",
            "Requirement already satisfied: zipp>=3.1.0 in /usr/local/lib/python3.7/dist-packages (from importlib-resources>=1.4.0->jsonschema!=2.5.0,>=2.4->nbformat>=4.2.0->ipywidgets~=7.6.5->medcat==1.2.7) (3.7.0)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->py2neo==2021.2.3->medcat==1.2.7) (3.0.7)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas<=1.3.4,>=1.1.5->medcat==1.2.7) (2.8.2)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.7/dist-packages (from prompt-toolkit<2.0.0,>=1.0.4->ipython>=4.0.0->ipywidgets~=7.6.5->medcat==1.2.7) (0.2.5)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->datasets~=1.14.0->medcat==1.2.7) (3.0.4)\n",
            "Collecting requests>=2.19.0\n",
            "  Downloading requests-2.27.1-py2.py3-none-any.whl (63 kB)\n",
            "\u001b[K     |████████████████████████████████| 63 kB 1.6 MB/s \n",
            "\u001b[?25hRequirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->datasets~=1.14.0->medcat==1.2.7) (2.10)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->datasets~=1.14.0->medcat==1.2.7) (2.0.11)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.7/dist-packages (from sklearn~=0.0->medcat==1.2.7) (1.0.2)\n",
            "Collecting pathy>=0.3.5\n",
            "  Downloading pathy-0.6.1-py3-none-any.whl (42 kB)\n",
            "\u001b[K     |████████████████████████████████| 42 kB 1.4 MB/s \n",
            "\u001b[?25hCollecting typer<0.5.0,>=0.3.0\n",
            "  Downloading typer-0.4.0-py3-none-any.whl (27 kB)\n",
            "Collecting thinc<8.1.0,>=8.0.9\n",
            "  Downloading thinc-8.0.13-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (628 kB)\n",
            "\u001b[K     |████████████████████████████████| 628 kB 71.1 MB/s \n",
            "\u001b[?25hRequirement already satisfied: jinja2 in /usr/local/lib/python3.7/dist-packages (from spacy<3.1.4,>=3.1.0->medcat==1.2.7) (2.11.3)\n",
            "Collecting spacy-legacy<3.1.0,>=3.0.8\n",
            "  Downloading spacy_legacy-3.0.8-py2.py3-none-any.whl (14 kB)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy<3.1.4,>=3.1.0->medcat==1.2.7) (2.0.6)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.7/dist-packages (from spacy<3.1.4,>=3.1.0->medcat==1.2.7) (1.0.6)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy<3.1.4,>=3.1.0->medcat==1.2.7) (3.0.6)\n",
            "Collecting catalogue<2.1.0,>=2.0.6\n",
            "  Downloading catalogue-2.0.6-py3-none-any.whl (17 kB)\n",
            "Requirement already satisfied: blis<0.8.0,>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from spacy<3.1.4,>=3.1.0->medcat==1.2.7) (0.4.1)\n",
            "Requirement already satisfied: wasabi<1.1.0,>=0.8.1 in /usr/local/lib/python3.7/dist-packages (from spacy<3.1.4,>=3.1.0->medcat==1.2.7) (0.9.0)\n",
            "Collecting srsly<3.0.0,>=2.4.1\n",
            "  Downloading srsly-2.4.2-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (451 kB)\n",
            "\u001b[K     |████████████████████████████████| 451 kB 57.7 MB/s \n",
            "\u001b[?25hCollecting pydantic!=1.8,!=1.8.1,<1.9.0,>=1.7.4\n",
            "  Downloading pydantic-1.8.2-cp37-cp37m-manylinux2014_x86_64.whl (10.1 MB)\n",
            "\u001b[K     |████████████████████████████████| 10.1 MB 48.0 MB/s \n",
            "\u001b[?25hRequirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers~=4.11.3->medcat==1.2.7) (2019.12.20)\n",
            "Collecting pyyaml\n",
            "  Downloading PyYAML-6.0-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (596 kB)\n",
            "\u001b[K     |████████████████████████████████| 596 kB 32.7 MB/s \n",
            "\u001b[?25hCollecting tokenizers<0.11,>=0.10.1\n",
            "  Downloading tokenizers-0.10.3-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (3.3 MB)\n",
            "\u001b[K     |████████████████████████████████| 3.3 MB 37.2 MB/s \n",
            "\u001b[?25hCollecting sacremoses\n",
            "  Downloading sacremoses-0.0.47-py2.py3-none-any.whl (895 kB)\n",
            "\u001b[K     |████████████████████████████████| 895 kB 49.6 MB/s \n",
            "\u001b[?25hRequirement already satisfied: click<9.0.0,>=7.1.1 in /usr/local/lib/python3.7/dist-packages (from typer<0.5.0,>=0.3.0->spacy<3.1.4,>=3.1.0->medcat==1.2.7) (7.1.2)\n",
            "Requirement already satisfied: notebook>=4.4.1 in /usr/local/lib/python3.7/dist-packages (from widgetsnbextension~=3.5.0->ipywidgets~=7.6.5->medcat==1.2.7) (5.3.1)\n",
            "Requirement already satisfied: nbconvert in /usr/local/lib/python3.7/dist-packages (from notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets~=7.6.5->medcat==1.2.7) (5.6.1)\n",
            "Requirement already satisfied: terminado>=0.8.1 in /usr/local/lib/python3.7/dist-packages (from notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets~=7.6.5->medcat==1.2.7) (0.13.1)\n",
            "Requirement already satisfied: Send2Trash in /usr/local/lib/python3.7/dist-packages (from notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets~=7.6.5->medcat==1.2.7) (1.8.0)\n",
            "Requirement already satisfied: pyzmq>=13 in /usr/local/lib/python3.7/dist-packages (from jupyter-client->ipykernel>=4.5.1->ipywidgets~=7.6.5->medcat==1.2.7) (22.3.0)\n",
            "Requirement already satisfied: ptyprocess in /usr/local/lib/python3.7/dist-packages (from terminado>=0.8.1->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets~=7.6.5->medcat==1.2.7) (0.7.0)\n",
            "Collecting yarl<2.0,>=1.0\n",
            "  Downloading yarl-1.7.2-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (271 kB)\n",
            "\u001b[K     |████████████████████████████████| 271 kB 48.5 MB/s \n",
            "\u001b[?25hCollecting async-timeout<5.0,>=4.0.0a3\n",
            "  Downloading async_timeout-4.0.2-py3-none-any.whl (5.8 kB)\n",
            "Collecting asynctest==0.13.0\n",
            "  Downloading asynctest-0.13.0-py3-none-any.whl (26 kB)\n",
            "Collecting frozenlist>=1.1.1\n",
            "  Downloading frozenlist-1.3.0-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (144 kB)\n",
            "\u001b[K     |████████████████████████████████| 144 kB 54.7 MB/s \n",
            "\u001b[?25hCollecting aiosignal>=1.1.2\n",
            "  Downloading aiosignal-1.2.0-py3-none-any.whl (8.2 kB)\n",
            "Collecting multidict<7.0,>=4.5\n",
            "  Downloading multidict-6.0.2-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (94 kB)\n",
            "\u001b[K     |████████████████████████████████| 94 kB 2.7 MB/s \n",
            "\u001b[?25hRequirement already satisfied: MarkupSafe>=0.23 in /usr/local/lib/python3.7/dist-packages (from jinja2->spacy<3.1.4,>=3.1.0->medcat==1.2.7) (2.0.1)\n",
            "Requirement already satisfied: entrypoints>=0.2.2 in /usr/local/lib/python3.7/dist-packages (from nbconvert->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets~=7.6.5->medcat==1.2.7) (0.4)\n",
            "Requirement already satisfied: pandocfilters>=1.4.1 in /usr/local/lib/python3.7/dist-packages (from nbconvert->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets~=7.6.5->medcat==1.2.7) (1.5.0)\n",
            "Requirement already satisfied: mistune<2,>=0.8.1 in /usr/local/lib/python3.7/dist-packages (from nbconvert->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets~=7.6.5->medcat==1.2.7) (0.8.4)\n",
            "Requirement already satisfied: testpath in /usr/local/lib/python3.7/dist-packages (from nbconvert->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets~=7.6.5->medcat==1.2.7) (0.5.0)\n",
            "Requirement already satisfied: defusedxml in /usr/local/lib/python3.7/dist-packages (from nbconvert->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets~=7.6.5->medcat==1.2.7) (0.7.1)\n",
            "Requirement already satisfied: bleach in /usr/local/lib/python3.7/dist-packages (from nbconvert->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets~=7.6.5->medcat==1.2.7) (4.1.0)\n",
            "Requirement already satisfied: webencodings in /usr/local/lib/python3.7/dist-packages (from bleach->nbconvert->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets~=7.6.5->medcat==1.2.7) (0.5.1)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers~=4.11.3->medcat==1.2.7) (1.1.0)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn->sklearn~=0.0->medcat==1.2.7) (3.1.0)\n",
            "Installing collected packages: multidict, frozenlist, yarl, urllib3, numpy, catalogue, asynctest, async-timeout, aiosignal, typer, srsly, scipy, requests, pyyaml, pydantic, fsspec, aiohttp, xxhash, tokenizers, thinc, spacy-legacy, sacremoses, pathy, pansi, pandas, monotonic, interchange, huggingface-hub, elastic-transport, transformers, torch, spacy, py2neo, psutil, jsonpickle, gensim, elasticsearch, datasets, aiofiles, medcat\n",
            "  Attempting uninstall: urllib3\n",
            "    Found existing installation: urllib3 1.24.3\n",
            "    Uninstalling urllib3-1.24.3:\n",
            "      Successfully uninstalled urllib3-1.24.3\n",
            "  Attempting uninstall: numpy\n",
            "    Found existing installation: numpy 1.19.5\n",
            "    Uninstalling numpy-1.19.5:\n",
            "      Successfully uninstalled numpy-1.19.5\n",
            "  Attempting uninstall: catalogue\n",
            "    Found existing installation: catalogue 1.0.0\n",
            "    Uninstalling catalogue-1.0.0:\n",
            "      Successfully uninstalled catalogue-1.0.0\n",
            "  Attempting uninstall: srsly\n",
            "    Found existing installation: srsly 1.0.5\n",
            "    Uninstalling srsly-1.0.5:\n",
            "      Successfully uninstalled srsly-1.0.5\n",
            "  Attempting uninstall: scipy\n",
            "    Found existing installation: scipy 1.4.1\n",
            "    Uninstalling scipy-1.4.1:\n",
            "      Successfully uninstalled scipy-1.4.1\n",
            "  Attempting uninstall: requests\n",
            "    Found existing installation: requests 2.23.0\n",
            "    Uninstalling requests-2.23.0:\n",
            "      Successfully uninstalled requests-2.23.0\n",
            "  Attempting uninstall: pyyaml\n",
            "    Found existing installation: PyYAML 3.13\n",
            "    Uninstalling PyYAML-3.13:\n",
            "      Successfully uninstalled PyYAML-3.13\n",
            "  Attempting uninstall: thinc\n",
            "    Found existing installation: thinc 7.4.0\n",
            "    Uninstalling thinc-7.4.0:\n",
            "      Successfully uninstalled thinc-7.4.0\n",
            "  Attempting uninstall: pandas\n",
            "    Found existing installation: pandas 1.3.5\n",
            "    Uninstalling pandas-1.3.5:\n",
            "      Successfully uninstalled pandas-1.3.5\n",
            "  Attempting uninstall: torch\n",
            "    Found existing installation: torch 1.10.0+cu111\n",
            "    Uninstalling torch-1.10.0+cu111:\n",
            "      Successfully uninstalled torch-1.10.0+cu111\n",
            "  Attempting uninstall: spacy\n",
            "    Found existing installation: spacy 2.2.4\n",
            "    Uninstalling spacy-2.2.4:\n",
            "      Successfully uninstalled spacy-2.2.4\n",
            "  Attempting uninstall: psutil\n",
            "    Found existing installation: psutil 5.4.8\n",
            "    Uninstalling psutil-5.4.8:\n",
            "      Successfully uninstalled psutil-5.4.8\n",
            "  Attempting uninstall: gensim\n",
            "    Found existing installation: gensim 3.6.0\n",
            "    Uninstalling gensim-3.6.0:\n",
            "      Successfully uninstalled gensim-3.6.0\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "yellowbrick 1.3.post1 requires numpy<1.20,>=1.16.0, but you have numpy 1.21.5 which is incompatible.\n",
            "torchvision 0.11.1+cu111 requires torch==1.10.0, but you have torch 1.9.1 which is incompatible.\n",
            "torchtext 0.11.0 requires torch==1.10.0, but you have torch 1.9.1 which is incompatible.\n",
            "torchaudio 0.10.0+cu111 requires torch==1.10.0, but you have torch 1.9.1 which is incompatible.\n",
            "google-colab 1.0.0 requires requests~=2.23.0, but you have requests 2.27.1 which is incompatible.\n",
            "datascience 0.10.6 requires folium==0.2.1, but you have folium 0.8.3 which is incompatible.\n",
            "albumentations 0.1.12 requires imgaug<0.2.7,>=0.2.5, but you have imgaug 0.2.9 which is incompatible.\u001b[0m\n",
            "Successfully installed aiofiles-0.8.0 aiohttp-3.8.1 aiosignal-1.2.0 async-timeout-4.0.2 asynctest-0.13.0 catalogue-2.0.6 datasets-1.14.0 elastic-transport-8.0.1 elasticsearch-8.0.0 frozenlist-1.3.0 fsspec-2022.1.0 gensim-4.1.2 huggingface-hub-0.0.19 interchange-2021.0.4 jsonpickle-2.0.0 medcat-1.2.7 monotonic-1.6 multidict-6.0.2 numpy-1.21.5 pandas-1.3.4 pansi-2020.7.3 pathy-0.6.1 psutil-5.9.0 py2neo-2021.2.3 pydantic-1.8.2 pyyaml-6.0 requests-2.27.1 sacremoses-0.0.47 scipy-1.7.1 spacy-3.1.3 spacy-legacy-3.0.8 srsly-2.4.2 thinc-8.0.13 tokenizers-0.10.3 torch-1.9.1 transformers-4.11.3 typer-0.4.0 urllib3-1.26.8 xxhash-2.0.2 yarl-1.7.2\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "numpy",
                  "pandas",
                  "psutil"
                ]
              }
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting en-core-web-md==3.1.0\n",
            "  Downloading https://github.com/explosion/spacy-models/releases/download/en_core_web_md-3.1.0/en_core_web_md-3.1.0-py3-none-any.whl (45.4 MB)\n",
            "\u001b[K     |████████████████████████████████| 45.4 MB 80 kB/s \n",
            "\u001b[?25hRequirement already satisfied: spacy<3.2.0,>=3.1.0 in /usr/local/lib/python3.7/dist-packages (from en-core-web-md==3.1.0) (3.1.3)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.7/dist-packages (from spacy<3.2.0,>=3.1.0->en-core-web-md==3.1.0) (4.62.3)\n",
            "Requirement already satisfied: numpy>=1.15.0 in /usr/local/lib/python3.7/dist-packages (from spacy<3.2.0,>=3.1.0->en-core-web-md==3.1.0) (1.21.5)\n",
            "Requirement already satisfied: pathy>=0.3.5 in /usr/local/lib/python3.7/dist-packages (from spacy<3.2.0,>=3.1.0->en-core-web-md==3.1.0) (0.6.1)\n",
            "Requirement already satisfied: typing-extensions<4.0.0.0,>=3.7.4 in /usr/local/lib/python3.7/dist-packages (from spacy<3.2.0,>=3.1.0->en-core-web-md==3.1.0) (3.10.0.2)\n",
            "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /usr/local/lib/python3.7/dist-packages (from spacy<3.2.0,>=3.1.0->en-core-web-md==3.1.0) (2.0.6)\n",
            "Requirement already satisfied: wasabi<1.1.0,>=0.8.1 in /usr/local/lib/python3.7/dist-packages (from spacy<3.2.0,>=3.1.0->en-core-web-md==3.1.0) (0.9.0)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.7/dist-packages (from spacy<3.2.0,>=3.1.0->en-core-web-md==3.1.0) (2.11.3)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from spacy<3.2.0,>=3.1.0->en-core-web-md==3.1.0) (57.4.0)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.7/dist-packages (from spacy<3.2.0,>=3.1.0->en-core-web-md==3.1.0) (2.27.1)\n",
            "Requirement already satisfied: srsly<3.0.0,>=2.4.1 in /usr/local/lib/python3.7/dist-packages (from spacy<3.2.0,>=3.1.0->en-core-web-md==3.1.0) (2.4.2)\n",
            "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<1.9.0,>=1.7.4 in /usr/local/lib/python3.7/dist-packages (from spacy<3.2.0,>=3.1.0->en-core-web-md==3.1.0) (1.8.2)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy<3.2.0,>=3.1.0->en-core-web-md==3.1.0) (3.0.6)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from spacy<3.2.0,>=3.1.0->en-core-web-md==3.1.0) (21.3)\n",
            "Requirement already satisfied: typer<0.5.0,>=0.3.0 in /usr/local/lib/python3.7/dist-packages (from spacy<3.2.0,>=3.1.0->en-core-web-md==3.1.0) (0.4.0)\n",
            "Requirement already satisfied: blis<0.8.0,>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from spacy<3.2.0,>=3.1.0->en-core-web-md==3.1.0) (0.4.1)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy<3.2.0,>=3.1.0->en-core-web-md==3.1.0) (2.0.6)\n",
            "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.8 in /usr/local/lib/python3.7/dist-packages (from spacy<3.2.0,>=3.1.0->en-core-web-md==3.1.0) (3.0.8)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.7/dist-packages (from spacy<3.2.0,>=3.1.0->en-core-web-md==3.1.0) (1.0.6)\n",
            "Requirement already satisfied: thinc<8.1.0,>=8.0.9 in /usr/local/lib/python3.7/dist-packages (from spacy<3.2.0,>=3.1.0->en-core-web-md==3.1.0) (8.0.13)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from catalogue<2.1.0,>=2.0.6->spacy<3.2.0,>=3.1.0->en-core-web-md==3.1.0) (3.7.0)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.0->spacy<3.2.0,>=3.1.0->en-core-web-md==3.1.0) (3.0.7)\n",
            "Requirement already satisfied: smart-open<6.0.0,>=5.0.0 in /usr/local/lib/python3.7/dist-packages (from pathy>=0.3.5->spacy<3.2.0,>=3.1.0->en-core-web-md==3.1.0) (5.2.1)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.2.0,>=3.1.0->en-core-web-md==3.1.0) (2.0.11)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.2.0,>=3.1.0->en-core-web-md==3.1.0) (1.26.8)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.2.0,>=3.1.0->en-core-web-md==3.1.0) (2021.10.8)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.2.0,>=3.1.0->en-core-web-md==3.1.0) (2.10)\n",
            "Requirement already satisfied: click<9.0.0,>=7.1.1 in /usr/local/lib/python3.7/dist-packages (from typer<0.5.0,>=0.3.0->spacy<3.2.0,>=3.1.0->en-core-web-md==3.1.0) (7.1.2)\n",
            "Requirement already satisfied: MarkupSafe>=0.23 in /usr/local/lib/python3.7/dist-packages (from jinja2->spacy<3.2.0,>=3.1.0->en-core-web-md==3.1.0) (2.0.1)\n",
            "Installing collected packages: en-core-web-md\n",
            "Successfully installed en-core-web-md-3.1.0\n",
            "\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
            "You can now load the package via spacy.load('en_core_web_md')\n"
          ]
        }
      ],
      "source": [
        "# Install MedCAT\n",
        "! pip install medcat==1.2.7\n",
        "# Get the scispacy model\n",
        "! python -m spacy download en_core_web_md"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LWScf8BW0BpY"
      },
      "source": [
        "**Restart the runtime if on colab, sometimes necessary after installing models**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "KByaUPYNk7gk"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "from medcat.vocab import Vocab\n",
        "from medcat.cdb import CDB\n",
        "from medcat.config import Config\n",
        "from medcat.cdb_maker import CDBMaker\n",
        "from medcat.cat import CAT"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "kKgZTiZxk7gp"
      },
      "outputs": [],
      "source": [
        "DATA_DIR = \"./data/\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IRLcv4dGIEbS",
        "outputId": "376d0532-2104-48c7-dd8a-c7f7be30994f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2022-02-15 14:55:02--  https://raw.githubusercontent.com/CogStack/MedCATtutorials/main/notebooks/introductory/data/cdb_simple.csv\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.110.133, 185.199.111.133, 185.199.109.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.110.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 50 [text/plain]\n",
            "Saving to: ‘./data/cdb_simple.csv’\n",
            "\n",
            "\rcdb_simple.csv        0%[                    ]       0  --.-KB/s               \rcdb_simple.csv      100%[===================>]      50  --.-KB/s    in 0s      \n",
            "\n",
            "2022-02-15 14:55:02 (2.10 MB/s) - ‘./data/cdb_simple.csv’ saved [50/50]\n",
            "\n",
            "--2022-02-15 14:55:02--  https://raw.githubusercontent.com/CogStack/MedCATtutorials/main/notebooks/introductory/data/cdb_advanced.csv\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.111.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 150 [text/plain]\n",
            "Saving to: ‘./data/cdb_advanced.csv’\n",
            "\n",
            "cdb_advanced.csv    100%[===================>]     150  --.-KB/s    in 0s      \n",
            "\n",
            "2022-02-15 14:55:02 (6.40 MB/s) - ‘./data/cdb_advanced.csv’ saved [150/150]\n",
            "\n",
            "--2022-02-15 14:55:02--  https://raw.githubusercontent.com/CogStack/MedCATtutorials/main/notebooks/introductory/data/vocab_data.txt\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 72 [text/plain]\n",
            "Saving to: ‘./data/vocab_data.txt’\n",
            "\n",
            "vocab_data.txt      100%[===================>]      72  --.-KB/s    in 0s      \n",
            "\n",
            "2022-02-15 14:55:03 (3.30 MB/s) - ‘./data/vocab_data.txt’ saved [72/72]\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Load files if in google colab, otherwise skip this step\n",
        "!wget https://raw.githubusercontent.com/CogStack/MedCATtutorials/main/notebooks/introductory/data/cdb_simple.csv -P ./data/\n",
        "!wget https://raw.githubusercontent.com/CogStack/MedCATtutorials/main/notebooks/introductory/data/cdb_advanced.csv -P ./data/\n",
        "!wget https://raw.githubusercontent.com/CogStack/MedCATtutorials/main/notebooks/introductory/data/vocab_data.txt -P ./data/"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Kj24ZU79D-xE"
      },
      "source": [
        "# MedCAT Components\n",
        "The medcat model requires 3 model components to run.\n",
        "1. Vocab\n",
        "2. CDB\n",
        "3. Config (cdb configuration)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9POZ_dwsk7gu"
      },
      "source": [
        "## Building a Vocabulary\n",
        "\n",
        "The first of the two required models when running MedCAT is a Vocabulary model (Vocab). The model is used for two things: (1) Spell checking; and (2) Word Embedding. \n",
        "\n",
        "The Vocab is very simple and you can easily build it from a file that is structured as below:\n",
        "```\n",
        "<token>\\t<word_count>\\t<vector_embedding_separated_by_spaces>\n",
        "```\n",
        "`token` - Usually a word or subword if you are using Byte Pair Encoding or something similar.\n",
        "\n",
        "`word_count` - The count for this word in your dataset or in any large dataset (wikipedia also works nicely).\n",
        "\n",
        "`vector_embedding_separated_by_spaces` - precalculated vector embedding, can be from Word2Vec or BERT\n",
        "\n",
        "---\n",
        "An example with 3-dimension embedding would be:\n",
        "```\n",
        "house\t34444\t 0.3232 0.123213 1.231231\n",
        "dog\t14444\t0.76762 0.76767 1.45454\n",
        ".\n",
        ".\n",
        ".\n",
        "```\n",
        "The file is basically a TSV, but should not have any heading. \n",
        "\n",
        "---\n",
        "\n",
        "**NOTE**: If spelling is important for your use-case, take care that there are no misspelt words in the Vocab."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "OgMSGHyhk7gv"
      },
      "outputs": [],
      "source": [
        "# Let's have a look at an example, I've created a small vocabulary with only 2 words (the ones from above)\n",
        "# Let's try to create a vocabulary from this two words.\n",
        "\n",
        "vocab = Vocab()\n",
        "vocab.add_words(DATA_DIR +'vocab_data.txt', replace=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xPl6ghXUk7gy"
      },
      "source": [
        "**And that is everything, with this we have built our vocab and no futher training is necessary.**\n",
        "\n",
        "---\n",
        "\n",
        "A couple of useful functions of the vocab are presented below"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HeVMPs5Zk7gy",
        "outputId": "85ad79ea-6396-48c8-be3c-8fde7418567d"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "dict_keys(['house', 'dog'])"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ],
      "source": [
        "# To see the words in the vocab\n",
        "vocab.vocab.keys()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TofkHoHo0XKU",
        "outputId": "4e363ee7-f236-4f3f-9736-ada443c251ed"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'dog': {'cnt': 14444, 'ind': 1, 'vec': array([0.76762, 0.76767, 1.45454])},\n",
              " 'house': {'cnt': 34444,\n",
              "  'ind': 0,\n",
              "  'vec': array([0.3232  , 0.123213, 1.231231])}}"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ],
      "source": [
        "vocab.vocab"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SclVqlDgk7g2",
        "outputId": "c6414dc5-5526-4adb-f8b6-4d277f18d6b5"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "dict_keys(['house', 'dog', 'test'])"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ],
      "source": [
        "# If you want to add words manually (one by one) use:\n",
        "vocab.add_word(\"test\", cnt=31, vec=[1.42, 1.44, 1.55], replace=True)\n",
        "vocab.vocab.keys()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JnCgpKrEk7g5",
        "outputId": "85386247-dce5-410d-f201-d5142e023af7"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0.3232  , 0.123213, 1.231231])"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ],
      "source": [
        "# To get a vector of word use:\n",
        "vocab.vec(\"house\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bO4IEvrJk7g8",
        "outputId": "fde40e49-8c98-49b1-c822-55b9fb4af7b1"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "34444"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ],
      "source": [
        "# Or to get the count\n",
        "vocab['house']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fLg63Z9Yk7g-",
        "outputId": "3104f355-5899-483c-eff0-8583cd42fe2c"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ],
      "source": [
        "# To check if a word is in the vocab:\n",
        "\"house\" in vocab"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xG3FCinSl_Sq"
      },
      "source": [
        "### Before we save the vocab model, we need to create the unigram table for negative sampling"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "wdC8eennmSM4"
      },
      "outputs": [],
      "source": [
        "# This is necessary after each change of the vocabulary (when we add new words)\n",
        "vocab.make_unigram_table()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o6itJcEXk7hA"
      },
      "source": [
        "### Save the Vocab model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "RgRtW7eqk7hB"
      },
      "outputs": [],
      "source": [
        "vocab.save(DATA_DIR + \"vocab.dat\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-YBbwcNUk7hD"
      },
      "source": [
        "### Load the Vocab model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "o_tOsE6ak7hE"
      },
      "outputs": [],
      "source": [
        "vocab = Vocab.load(DATA_DIR + \"vocab.dat\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ptRmHln9k7hG"
      },
      "source": [
        "## Building the Concept Database (CDB)\n",
        "\n",
        "The second model we are going to need when using MedCAT is the Concept Database (CDB). This database holds a list of all concepts that we would like to detect and link to. For a lot of medical use-cases we would use giant databases like the UMLS or SNOMED CT. However, MedCAT can be used with any database no matter how big/small it is. \n",
        "\n",
        "To prepare the CDB we start off with a CSV with the following structure:\n",
        "```\n",
        "cui,name\n",
        "1,kidney failure\n",
        "7,CoVid 2\n",
        "7,coronavirus\n",
        "```\n",
        "This is the most basic version of the CSV file, it has only:\n",
        "\n",
        "`cui` - The concept unique identifier, this is simply an `ID` in your database.\n",
        "\n",
        "`name` - String/Name of that concept. It is important to write all possible names and abbreviations for a concept of interest.\n",
        "\n",
        "If you have a concept that can be recognised through multiple different names (like the one above with cui=7), you can simply add multiple rows with the same concept ID and MedCAT will merge that during the build phase.\n",
        "\n",
        "## The Full CSV Specification\n",
        "```\n",
        "cui,name,ontologies,name_status,type_ids,description\n",
        "1,Kidney Failure,SNOMED,P,T047,kidneys stop working\n",
        ".\n",
        ".\n",
        ".\n",
        "```\n",
        "The rest of the fields are optional, each can be included or left out in your CSV:\n",
        "\n",
        "`ontologies` - Source ontology, e.g. HPO, SNOMED, HPC,...\n",
        "\n",
        "`name_status` - Term type e.g. P - Primary Name. Primary names are important and I would always recommend to add this fields when creating your CDB. This will help distinguish between synonyms.\n",
        "\n",
        "`type_ids` - Type Ids are the broad category in which a concept may fall under. This is used to rapidly filter for concepts which fall under a specific category. In UMLS this could be the Semantic type identifier - e.g. T047 (taken from UMLS). A list of all semantic types can be found [here](https://metamap.nlm.nih.gov/Docs/SemanticTypes_2018AB.txt).\n",
        "In SNOMED one could use the Semantic tags. E.g (Disease). A list of all Snomed semantic tags can be found [here](https://confluence.ihtsdotools.org/display/DOCGLOSS/semantic+tag).\n",
        "\n",
        "\n",
        "`description` - Description of this concept\n",
        "\n",
        "***Note***: If one concept has multiple names, you can also separate the different names by a \"|\" - pipe - symbol "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "y5IR-xFO4oph"
      },
      "outputs": [],
      "source": [
        "cdb_simple = pd.read_csv(DATA_DIR + 'cdb_simple.csv')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 143
        },
        "id": "tHr26s3s4vJN",
        "outputId": "79cab9f5-186e-4fa9-87aa-d8c6fb569cc0"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-c6597ccf-360d-462e-84ea-9db5e86bd2bb\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>cui</th>\n",
              "      <th>name</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>kidney failure</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>7</td>\n",
              "      <td>CoVid 2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>7</td>\n",
              "      <td>coronavirus</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-c6597ccf-360d-462e-84ea-9db5e86bd2bb')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-c6597ccf-360d-462e-84ea-9db5e86bd2bb button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-c6597ccf-360d-462e-84ea-9db5e86bd2bb');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "   cui            name\n",
              "0    1  kidney failure\n",
              "1    7         CoVid 2\n",
              "2    7     coronavirus"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ],
      "source": [
        "cdb_simple"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Rasu5PajojYZ"
      },
      "source": [
        "Let's try building our own concept databse from a simple CSV"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "y75WVeca08z3"
      },
      "outputs": [],
      "source": [
        "# First initialise the default configuration\n",
        "config = Config()\n",
        "config.general['spacy_model'] = 'en_core_web_md'\n",
        "maker = CDBMaker(config)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "op5-LDOfk7hH",
        "outputId": "e1577914-aed4-42d4-fc54-70fe422a1304"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Started importing concepts from: ./data/cdb_advanced.csv\n",
            "Current progress: 0% at 0.000s per 0 rows\n",
            "Current progress: 50% at 0.024s per 0 rows\n",
            "Started importing concepts from: ./data/cdb_simple.csv\n",
            "Current progress: 0% at 0.000s per 0 rows\n",
            "Current progress: 33% at 0.009s per 0 rows\n",
            "Current progress: 67% at 0.008s per 0 rows\n"
          ]
        }
      ],
      "source": [
        "# Create an array containing CSV files that will be used to build our CDB\n",
        "csv_path = [ DATA_DIR + 'cdb_advanced.csv', DATA_DIR + 'cdb_simple.csv',]\n",
        "\n",
        "# Create your CDB\n",
        "cdb = maker.prepare_csvs(csv_path, full_build=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "08agsFBnk7hQ"
      },
      "source": [
        "**That is all, nothing else is necessary to build the CDB**\n",
        "\n",
        "---\n",
        "\n",
        "Some useful functions of the cdb are below"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lwlOBilek7hJ",
        "outputId": "7ec126f6-16e4-4d18-e613-4eca9ea25e5b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'kidney~failure': ['1'], 'failure~of~kidneys': ['1'], 'failure~of~kidney': ['1'], 'kf': ['1'], 'k~.~failure': ['1'], 'covid~2': ['7'], 'coronavirus': ['7']}\n"
          ]
        }
      ],
      "source": [
        "# To display all names and cui in the db\n",
        "print(cdb.name2cuis)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uD3AYqqkk7hQ",
        "outputId": "b6f11c70-1817-4fb2-ba11-4d8a8c87b0d5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'1': {'failure~of~kidney', 'failure~of~kidneys', 'kidney~failure', 'kf', 'k~.~failure'}, '7': {'covid~2', 'coronavirus'}}\n"
          ]
        }
      ],
      "source": [
        "# To display all unique cuis and corresponding names in the db \n",
        "print(cdb.cui2names)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GWTRmz_duRT2",
        "outputId": "1d5faeb9-5a34-4c83-fc46-e211fa65478f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'1': 'Kidney Failure'}\n"
          ]
        }
      ],
      "source": [
        "# To display cui to preferred name\n",
        "print(cdb.cui2preferred_name)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "j18tyQ2Kk7hV",
        "outputId": "6116fe26-d633-4b0f-c241-126a4b5d918a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'1': {'T047'}, '7': set()}\n"
          ]
        }
      ],
      "source": [
        "# We have a link from cui to type ids\n",
        "print(cdb.cui2type_ids)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Lpx7zGvwk7ha"
      },
      "source": [
        "### Save the Concept Database model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "fC01maOzk7ha"
      },
      "outputs": [],
      "source": [
        "cdb.save(DATA_DIR + \"cdb.dat\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "97uiDwvAk7hc"
      },
      "source": [
        "### Load the Concept Database model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "J9Ft8PbFk7hc"
      },
      "outputs": [],
      "source": [
        "cdb = CDB.load(DATA_DIR + \"cdb.dat\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0xqmmAue-UE4"
      },
      "source": [
        "## Setting the CDB configuration\n",
        "\n",
        "The CDB config sets the model parameters.\n",
        "This allows you to tailor the model to your own specific use case. Although the default configuration will suit the majority of use cases."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "eH1xiXvG-aWR"
      },
      "outputs": [],
      "source": [
        "# For further information on the cdb configuration options and explore what the default options are.\n",
        "??cdb.config"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "id": "-aLoW6ltAa6l"
      },
      "outputs": [],
      "source": [
        "# Set a couple of parameters, they are usually set via environments, but\n",
        "#here we will do it explicitly. You can read more about each option in the \n",
        "#medcat repository: https://github.com/CogStack/MedCAT\n",
        "\n",
        "cdb.config.ner['min_name_len'] = 2\n",
        "cdb.config.ner['upper_case_limit_len'] = 3\n",
        "cdb.config.general['spell_check'] = True\n",
        "cdb.config.linking['train_count_threshold'] = 10\n",
        "cdb.config.linking['similarity_threshold'] = 0.3\n",
        "cdb.config.linking['train'] = True\n",
        "cdb.config.linking['disamb_length_limit'] = 5\n",
        "cdb.config.general['full_unlink'] = True"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cqmVITvWCIr6"
      },
      "source": [
        "Note: Don't forget to save the cdb with the new configurations if you want to reuse them!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DZvhmkIL8433"
      },
      "source": [
        "# Create a MedCAT model pack\n",
        "\n",
        "A MedCAT model pack is an easy way to store all the various components of a MedCAT model in one place.\n",
        "\n",
        "This includes the CDB, CDB configurations, Vocab, and even various MetaCAT models! We will learn more about the latter in the following tutorials."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "id": "LxcW2GcM-c-M"
      },
      "outputs": [],
      "source": [
        "# Initialise the model\n",
        "cat = CAT(cdb=cdb, config=cdb.config, vocab=vocab)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 936
        },
        "id": "-cXusFuI-drw",
        "outputId": "936c8e74-c452-47bf-ea78-365394af1044"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Please consider populating the version information [description, performance, location, ontology] in cat.config.version\n",
            "/usr/local/lib/python3.7/dist-packages/numpy/lib/function_base.py:380: RuntimeWarning: Mean of empty slice.\n",
            "  avg = a.mean(axis)\n",
            "/usr/local/lib/python3.7/dist-packages/numpy/core/_methods.py:170: RuntimeWarning: invalid value encountered in double_scalars\n",
            "  \n",
            "Please consider updating [description, performance, location, ontology] in cat.config.version\n",
            "This will save all models into a zip file, can take some time and require quite a bit of disk space.\n",
            "{\n",
            "  \"Model ID\": \"1c110382a5935e53\",\n",
            "  \"Last Modifed On\": \"15 February 2022\",\n",
            "  \"History (from least to most recent)\": [],\n",
            "  \"Description\": \"No description\",\n",
            "  \"Source Ontology\": null,\n",
            "  \"Location\": null,\n",
            "  \"MetaCAT models\": {},\n",
            "  \"Basic CDB Stats\": {\n",
            "    \"Number of concepts\": 2,\n",
            "    \"Number of names\": 7,\n",
            "    \"Number of concepts that received training\": 0,\n",
            "    \"Number of seen training examples in total\": 0,\n",
            "    \"Average training examples per concept\": NaN\n",
            "  },\n",
            "  \"Performance\": {\n",
            "    \"ner\": {},\n",
            "    \"meta\": {}\n",
            "  },\n",
            "  \"Important Parameters (Partial view, all available in cat.config)\": {\n",
            "    \"config.ner['min_name_len']\": {\n",
            "      \"value\": 2,\n",
            "      \"description\": \"Minimum detection length (found terms/mentions shorter than this will not be detected).\"\n",
            "    },\n",
            "    \"config.ner['upper_case_limit_len']\": {\n",
            "      \"value\": 3,\n",
            "      \"description\": \"All detected terms shorter than this value have to be uppercase, otherwise they will be ignored.\"\n",
            "    },\n",
            "    \"config.linking['similarity_threshold']\": {\n",
            "      \"value\": 0.3,\n",
            "      \"description\": \"If the confidence of the model is lower than this a detection will be ignore.\"\n",
            "    },\n",
            "    \"config.general['spell_check']\": {\n",
            "      \"value\": true,\n",
            "      \"description\": \"Is spell checking enabled.\"\n",
            "    },\n",
            "    \"config.general['spell_check_len_limit']\": {\n",
            "      \"value\": 7,\n",
            "      \"description\": \"Words shorter than this will not be spell checked.\"\n",
            "    }\n",
            "  }\n",
            "}\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'medcat_model_pack_1c110382a5935e53'"
            ]
          },
          "metadata": {},
          "execution_count": 28
        }
      ],
      "source": [
        "# Create and save a model pack\n",
        "cat.create_model_pack(DATA_DIR + \"my_first_medcat_modelpack\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9fwiKys4k7he"
      },
      "source": [
        "# End\n",
        "\n",
        "This is everything you need to create your own MedCAT models. In the following tutorials you will learn how to uses modelpacks to train models and use them to annotate documents. "
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "name": "MedCAT Tutorial | Part 3.1 Building a Concept Database and Vocabulary.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}